{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "De2Vj58qdF5e",
        "trCVnAu9R1_o"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_O7wFnNNtn2"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAoHgIe3RxCH",
        "outputId": "1c13dceb-7f78-44f0-ee02-802a4d8912bb"
      },
      "source": [
        "!pip install seaborn\n",
        "!pip install causalgraphicalmodels\n",
        "!pip install matplotlib\n",
        "!pip install -U scikit-learn\n",
        "!pip install --upgrade tensorflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import seaborn as sns\n",
        "import causalgraphicalmodels\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
            "Collecting causalgraphicalmodels\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/ee/3b2d184576f3cb4873cebfc696e8e5c1e53eaef691f38aea76c206f9f916/causalgraphicalmodels-0.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels) (1.1.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from causalgraphicalmodels) (2.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->causalgraphicalmodels) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->causalgraphicalmodels) (2.8.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->causalgraphicalmodels) (4.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->causalgraphicalmodels) (1.15.0)\n",
            "Installing collected packages: causalgraphicalmodels\n",
            "Successfully installed causalgraphicalmodels-0.0.4\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.1.0\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDeFoeRyN6l8"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY0eEtIiRJK3"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return (1 / (1 + math.exp(-x)))\n",
        "def epsilon_x ():\n",
        "    return np.random.normal(loc = 0,scale = 0.5)\n",
        "def epsilon_y ():\n",
        "    return np.random.normal(loc = 0 , scale = 1)\n",
        "def epsilon_z ():\n",
        "    return np.random.normal(loc=-1,scale=1)\n",
        "def para_c1():\n",
        "    return np.random.normal(loc=-2,scale=1)\n",
        "def para_c2():\n",
        "    return np.random.normal(loc=-2,scale = 1)\n",
        "def para_cy():\n",
        "    return np.random.normal(loc=1,scale=1)\n",
        "\n",
        "def build_x(u):\n",
        "    return np.random.binomial(n=1,p=sigmoid(u + epsilon_x()))\n",
        "\n",
        "def build_causal_model(n_samples,d):\n",
        "    scm_fd = np.empty((n_samples,d+2))\n",
        "    col_name = list()\n",
        "    for i in range(n_samples):\n",
        "        u1 = np.random.normal(loc=-2 ,scale = 1)\n",
        "        x = build_x(u1)\n",
        "        scm_fd[i][0] = x\n",
        "        if i == 0:\n",
        "          col_name.append('x')\n",
        "        z_sum = 0.0\n",
        "        for j in range(1,d+1,1):\n",
        "            p=sigmoid(para_c1() + para_c2() *x + epsilon_z())\n",
        "            z = np.random.binomial(n=1,p=p)\n",
        "            scm_fd[i][j] = z\n",
        "            p = para_cy()\n",
        "            z_sum += z*p\n",
        "            if i==0:\n",
        "              col_name.append('z'+str(j-1))\n",
        "        y = sigmoid(2*z_sum + u1 + epsilon_y())\n",
        "        scm_fd[i][d+1] = y\n",
        "        if i == 0:\n",
        "          col_name.append('y')\n",
        "    return scm_fd,col_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPNDFGeEOECQ"
      },
      "source": [
        "# Ground Truth (Do Calculus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAviUFvjRVok"
      },
      "source": [
        "def causal_do(df,new_x):\n",
        "    scm_copy = df.copy()\n",
        "    scm_copy[:,0] = new_x\n",
        "    for i in range(scm_copy.shape[0]):\n",
        "        u1 = np.random.normal(loc = -2, scale = 1)\n",
        "        x = new_x[i]\n",
        "        #print(x)\n",
        "        z_sum = 0.0\n",
        "        d = scm_copy.shape[1] - 2\n",
        "        for j in range(1,d+1,1):\n",
        "            p=sigmoid(para_c1() + para_c2() *x + epsilon_z())\n",
        "            z = np.random.binomial(n=1,p=p)\n",
        "            scm_copy[i][j] = z\n",
        "            z_sum += z*para_cy()\n",
        "        y = sigmoid(2*z_sum + u1 + epsilon_y())\n",
        "        scm_copy[i][d+1] = y\n",
        "\n",
        "    print('modified')\n",
        "    print(scm_copy)\n",
        "\n",
        "    return scm_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlsL1z4_pREd"
      },
      "source": [
        "**Estimate E[Y|X=1] - E[Y|X=0]**\n",
        "from a dataframe `df` of samples.\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS6VgHGURdAI"
      },
      "source": [
        "def estimate_conditional_expectation1(df):\n",
        "    scm_cols = np.size(df,axis=1)\n",
        "    scm_rows = np.size(df,axis=0)\n",
        "    a = df[:,0] == 0\n",
        "    b = df[:,0] == 1\n",
        "    y = df[:,df.shape[1]-1]\n",
        "\n",
        "    p = np.mean(y[b])\n",
        "    q = np.mean(y[a])\n",
        "    delta = p-q\n",
        "    return p,q,delta\n",
        "def ab_test1(scm, n):\n",
        "    n_a = int(n / 2)\n",
        "    n_b = n - n_a\n",
        "    set_variable = np.array([0]*n_a + [1]*n_b)\n",
        "    scm = causal_do(scm,set_variable)\n",
        "    # print('modified->',scm)\n",
        "    return estimate_conditional_expectation1(scm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "156bUxe2FKUx"
      },
      "source": [
        "# ATE using CWO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCpnUDHcm6Jx"
      },
      "source": [
        "**Weight Generattion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcS9ltL-300U"
      },
      "source": [
        "def estimate_p_z_x(df):\n",
        "  d = df.shape[1]-3\n",
        "  df_copy = df.copy()\n",
        "  df_size = df.shape[0]\n",
        "  proba_z_x = np.ones(df.shape[0])\n",
        "  X=df['x'].values.reshape(-1, 1)\n",
        "\n",
        "  for i in range(d):\n",
        "\n",
        "    y=df[('z'+str(i))]\n",
        "    #print(i , y)\n",
        "    clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "    predict = clf.predict_proba(X)\n",
        "    for j in range(df_size):\n",
        "      proba_z_x[j] *= predict[j,int(y[j])]\n",
        "    del clf\n",
        "\n",
        "    #print(proba_z_x)\n",
        "  prob_frame = pd.DataFrame(proba_z_x , columns = [\"z|x\"])\n",
        "  #print(prob_frame)\n",
        "\n",
        "  return prob_frame\n",
        "\n",
        "\n",
        "def prob_z(data):\n",
        "  d=data.shape[1]-3\n",
        "  z=data.iloc[:,1:1+d]\n",
        "  # d = z.shape[1]\n",
        "  l=z.shape[0]\n",
        "  p={}\n",
        "  for i in range(d):\n",
        "    p[i]={}\n",
        "    prob = z['z'+str(i)] == 0\n",
        "    p[i][0]= prob.mean()\n",
        "    prob = z['z'+str(i)] == 1\n",
        "    p[i][1]= prob.mean()\n",
        "  pz=np.ones(l)\n",
        "  for i in range(l):\n",
        "    for j in range(d):\n",
        "      pz[i]*=p[j][z.loc[i][j]]\n",
        "  z_hat = pd.DataFrame(pz,columns =['z_hat'])\n",
        "  return z_hat\n",
        "\n",
        "\n",
        "def weightGenerator(df):\n",
        "  data=df.copy()\n",
        "  data1 = estimate_p_z_x(data).to_numpy()\n",
        "  data2 = prob_z(data).to_numpy()\n",
        "  data_prob = np.divide(data2,data1)\n",
        "  return data_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09TKD-SuRHd4"
      },
      "source": [
        "def cwoBeta(X,y,weight,beta):\n",
        "  Beta1 = LinearRegression().fit(X,y,sample_weight=weight)\n",
        "  test_x=np.array([0, 1]).reshape((-1, 1))\n",
        "  if beta==1:\n",
        "    y_pred=Beta1.predict(test_x)\n",
        "  else:\n",
        "    y_pred=Beta1.predict(X)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpPh2APKlw1U"
      },
      "source": [
        "def weightedATE(df):\n",
        "  data=df.copy()\n",
        "  d=data.shape[1]-3\n",
        "  Z=data.iloc[:,1:1+d].values.reshape(-1, d)\n",
        "  X=data['x'].values.reshape(-1, 1)\n",
        "  Y=data['y'].values.reshape(-1, 1)\n",
        "  data['weight'] = weightGenerator(data)\n",
        "  sampleWeight= data['weight']\n",
        "  y_pred=cwoBeta(Z,Y,sampleWeight,2)\n",
        "  sampleWeight2 =np.ones((df.shape[0],), dtype=int)\n",
        "  ate=cwoBeta(X,y_pred,sampleWeight2,1)\n",
        "  return ate[1],ate[0],ate[1]-ate[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B4q7vdns57F"
      },
      "source": [
        "# NeuralNetwork ATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Hnaw38xVZG"
      },
      "source": [
        "#low d\n",
        "\n",
        "hpDict={'conv_0_units': 10,\n",
        " 'conv_1_units': 10,\n",
        " 'dropout': 0.1,\n",
        " 'dropout_0_': 0.1,\n",
        " 'dropout_1_': 0.1,\n",
        " 'input_units': 80,\n",
        " 'learning_rate': 0.0006794707285250219,\n",
        " 'n_layers': 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvfGLewKRhd-"
      },
      "source": [
        "#high d\n",
        "\n",
        "hpDict={'conv_0_units': 70,\n",
        " 'conv_1_units': 80,\n",
        " 'conv_2_units': 10,\n",
        " 'dropout': 0,\n",
        " 'dropout_0_': 0.2,\n",
        " 'dropout_1_': 0.10000000000000004,\n",
        " 'dropout_2_': 0.1,\n",
        " 'input_units': 90,\n",
        " 'learning_rate': 0.0003239508297196215,\n",
        " 'n_layers': 3}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8htzojsOTot"
      },
      "source": [
        "def nnBeta(X,y,weight,hp):\n",
        "  d=X.shape[1]\n",
        "  Beta2 = tf.keras.models.Sequential()\n",
        "  Beta2.add(tf.keras.layers.Dense(hp['input_units'],activation='relu',input_shape=(d,)))\n",
        "  Beta2.add(tf.keras.layers.Dropout(hp['dropout']))\n",
        "  for i in range(hp['n_layers']):\n",
        "    Beta2.add(tf.keras.layers.Dense(hp[f'conv_{i}_units'], activation='relu'))\n",
        "    Beta2.add(tf.keras.layers.Dropout(hp[f'dropout_{i}_']))\n",
        "\n",
        "  Beta2.add(tf.keras.layers.Dense(1, activation='linear'))\n",
        "  Beta2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=hp['learning_rate']), loss='mse')\n",
        "\n",
        "  early_stop=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20, verbose=1, mode='auto', restore_best_weights=True)\n",
        "  history=Beta2.fit(X,y,epochs=1000,\n",
        "                    validation_split=0.2,\n",
        "                    shuffle = True,\n",
        "                    callbacks=[early_stop],\n",
        "                    verbose=0\n",
        "                    ,sample_weight=weight\n",
        "                    )\n",
        "  y_pred = Beta2.predict(X)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9DHgZpoI8Le"
      },
      "source": [
        "def NeuralATE(df,hp):\n",
        "  data=df.copy()\n",
        "  d=data.shape[1]-2\n",
        "  Z=data.iloc[:,1:d+1].values.reshape(-1, d)\n",
        "  X=data['x'].values.reshape(-1, 1)\n",
        "  Y=data['y'].values.reshape(-1, 1)\n",
        "  sampleWeight = weightGenerator(data)\n",
        "  y_pred = nnBeta(Z,Y,sampleWeight,hp)\n",
        "  sampleWeight2 =np.ones((df.shape[0],), dtype=int)\n",
        "  ate=cwoBeta(X,y_pred,sampleWeight2,1)\n",
        "  return ate[1][0],ate[0][0],ate[1][0]-ate[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trCVnAu9R1_o"
      },
      "source": [
        "# mu and Dataframe saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evyC72USO8Lu",
        "outputId": "da68b95e-04ff-4b74-9e31-040cf02fbfcb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9MJkjIyYJnH",
        "outputId": "c0f753ed-4698-4d81-bda7-44f4f99c6021"
      },
      "source": [
        "%cd drive/My Drive/\n",
        "%cd Datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/'\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8SH7FJuS-F5"
      },
      "source": [
        "D=6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTZwWd-IGHaB"
      },
      "source": [
        "def doDo(d):\n",
        "  N=10000000\n",
        "  fdDo,col_name=build_causal_model(N,d)\n",
        "  mu1,mu0,muATE=ab_test1(fdDo, N)\n",
        "  df = pd.DataFrame(fdDo,columns = col_name)\n",
        "  return df,mu1,mu0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmkcMH5hrESG",
        "outputId": "cff669b1-cdca-483a-c82f-f35858bef0ab"
      },
      "source": [
        "fd,mu1,mu0=doDo(D)\n",
        "print(\"Estimated ATE: {:.3f}\".format(mu1-mu0))\n",
        "print(\"mu(1): {:.3f}\".format(mu1))\n",
        "print(\"mu(0): {:.3f}\".format(mu0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "modified\n",
            "[[0.         0.         0.         ... 0.         0.         0.09138255]\n",
            " [0.         0.         0.         ... 0.         0.         0.01437216]\n",
            " [0.         0.         0.         ... 0.         0.         0.06594632]\n",
            " ...\n",
            " [1.         0.         0.         ... 0.         0.         0.15628845]\n",
            " [1.         0.         0.         ... 0.         0.         0.0598134 ]\n",
            " [1.         0.         0.         ... 0.         0.         0.10109322]]\n",
            "Estimated ATE: -0.116\n",
            "mu(1): 0.229\n",
            "mu(0): 0.344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDmPMn1mwZBQ"
      },
      "source": [
        "fd.to_pickle(\"drive/MyDrive/Datasets/f_dataframe_6.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWYymiikw9Zv",
        "outputId": "26104481-dccc-497a-d184-8aff78832f99"
      },
      "source": [
        "string1 = str(mu1) + \" \" + str(mu0)\n",
        "print(string1)\n",
        "f = open(\"drive/MyDrive/Datasets/f_mu_6.txt\",\"w\")\n",
        "f.write(string1)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.22851276750896699 0.3444887749881229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGi7yObEYoKw"
      },
      "source": [
        "# Result Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpRkaDZEPTjp",
        "outputId": "9821cd0b-4bf6-4b18-fc61-3ef971513fad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grZKHoenx-Rt",
        "outputId": "481dae98-833c-4f89-f0d0-8fcaf05d31a4"
      },
      "source": [
        "fd = pd.read_pickle(\"drive/MyDrive/Datasets/f_dataframe_10.pkl\")\n",
        "print(fd)\n",
        "f = open('drive/MyDrive/Datasets/f_mu_10.txt','r')\n",
        "mm = f.read()\n",
        "mu1,mu0 = mm.split()\n",
        "mu1=float(mu1)\n",
        "mu0=float(mu0)\n",
        "print(mu1,mu0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           x   z0   z1   z2   z3   z4   z5   z6   z7   z8   z9         y\n",
            "0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.120565\n",
            "1        0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.999094\n",
            "2        1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.232915\n",
            "3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.033733\n",
            "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.218860\n",
            "...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...\n",
            "9999995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.102548\n",
            "9999996  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.184443\n",
            "9999997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.242544\n",
            "9999998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.321488\n",
            "9999999  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.242391\n",
            "\n",
            "[10000000 rows x 12 columns]\n",
            "0.25690356479199317 0.4349996790635731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1UirzssDHW_"
      },
      "source": [
        "def MAAEgenerator(fd,mu1,mu0):\n",
        "  muN1,muN0,_=NeuralATE(fd,hpDict)\n",
        "  muC1,muC0,_=weightedATE(fd)\n",
        "  maaeN=(abs(muN1-mu1)+abs(muN0-mu0))/2\n",
        "  maaeC=(abs(muC1-mu1)+abs(muC0-mu0))/2\n",
        "  return maaeN,maaeC\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btk827wNrACe"
      },
      "source": [
        "N_SAMPLE=2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqQt5CkarYeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78220c4-4e10-4686-bad8-0b40fe8f7006"
      },
      "source": [
        "muN=np.zeros(100)\n",
        "muC=np.zeros(100)\n",
        "for k in range(100):\n",
        "  print(\"K= \",k)\n",
        "  db=fd.sample(n=N_SAMPLE).reset_index(drop=True)\n",
        "  muN[k],muC[k]=MAAEgenerator(db,mu1,mu0)\n",
        "  print(k,muN[k],muC[k])\n",
        "MAAE_N=np.median(muN)\n",
        "print(\"MAAE NN\",MAAE_N)\n",
        "MAAE_C=np.median(muC)\n",
        "print(\"MAAE CWO\",MAAE_C)\n",
        "print(\"MAAE NN: {:.5f}\".format(MAAE_N))\n",
        "print(\"MAAE CWO: {:.5f}\".format(MAAE_C))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K=  0\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00036: early stopping\n",
            "0 0.014967302938202226 0.02036279517435255\n",
            "K=  1\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "1 0.005050455816114463 0.014693580910319165\n",
            "K=  2\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "2 0.005337448987116772 0.015479276413675164\n",
            "K=  3\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "3 0.01991343083251254 0.018599353887328585\n",
            "K=  4\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00035: early stopping\n",
            "4 0.024148787391648413 0.01979394493596251\n",
            "K=  5\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00045: early stopping\n",
            "5 0.015096315566239138 0.015705890843967896\n",
            "K=  6\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00040: early stopping\n",
            "6 0.01721391216548568 0.02566606315579048\n",
            "K=  7\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "7 0.018233549449131664 0.012710854165267932\n",
            "K=  8\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00088: early stopping\n",
            "8 0.00797608214410614 0.016336823563742775\n",
            "K=  9\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n",
            "9 0.017575505281196224 0.019879616094982705\n",
            "K=  10\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "10 0.019408452133859222 0.02262575563174482\n",
            "K=  11\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n",
            "11 0.011877957491737645 0.02254651634112853\n",
            "K=  12\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "12 0.008863012335803389 0.017402590957469544\n",
            "K=  13\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "13 0.01516864115002145 0.02171725156031387\n",
            "K=  14\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "14 0.01586954376059746 0.02851514557851681\n",
            "K=  15\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "15 0.005624608504281564 0.010330891589261343\n",
            "K=  16\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00040: early stopping\n",
            "16 0.017560924516748178 0.02453441837985365\n",
            "K=  17\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00054: early stopping\n",
            "17 0.009607778491381003 0.01282405588358354\n",
            "K=  18\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00039: early stopping\n",
            "18 0.008614404500330686 0.011034275390735843\n",
            "K=  19\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00034: early stopping\n",
            "19 0.012320230033906449 0.02042226603872635\n",
            "K=  20\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "20 0.02205466834105052 0.012148244958196802\n",
            "K=  21\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00046: early stopping\n",
            "21 0.012951781254591926 0.02858470421232548\n",
            "K=  22\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00058: early stopping\n",
            "22 0.009550594546050728 0.012951369636217847\n",
            "K=  23\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00037: early stopping\n",
            "23 0.01223458427921345 0.015519617918842599\n",
            "K=  24\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00048: early stopping\n",
            "24 0.005881808037189962 0.019301348195718382\n",
            "K=  25\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "25 0.010403303680158765 0.017121736938922105\n",
            "K=  26\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "26 0.006772753351983213 0.007418818315388265\n",
            "K=  27\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "27 0.011759107855536466 0.013427369405680678\n",
            "K=  28\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00040: early stopping\n",
            "28 0.012826016162158838 0.017971539847628448\n",
            "K=  29\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00064: early stopping\n",
            "29 0.011571642209217387 0.01385031597897976\n",
            "K=  30\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "30 0.013359470869534679 0.01700361455047167\n",
            "K=  31\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00039: early stopping\n",
            "31 0.0054961258724736395 0.00778617896057146\n",
            "K=  32\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "32 0.026032983560690462 0.01505939724272995\n",
            "K=  33\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "33 0.011230783531666344 0.016831249792362418\n",
            "K=  34\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "34 0.011396569747022328 0.019100472864079565\n",
            "K=  35\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00043: early stopping\n",
            "35 0.008924915837356356 0.014119404029224486\n",
            "K=  36\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n",
            "36 0.014470004422593608 0.020449985473530524\n",
            "K=  37\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "37 0.01837739782235176 0.02330022152976363\n",
            "K=  38\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00042: early stopping\n",
            "38 0.02716393872749498 0.02210443372290949\n",
            "K=  39\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "39 0.012343983935607983 0.014323325171797519\n",
            "K=  40\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "40 0.022684836667422326 0.01870861102203672\n",
            "K=  41\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "41 0.00938494428026762 0.01600712328690493\n",
            "K=  42\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n",
            "42 0.014908051965804747 0.017931529394780127\n",
            "K=  43\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00025: early stopping\n",
            "43 0.01655457243739586 0.022673864718443043\n",
            "K=  44\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00037: early stopping\n",
            "44 0.005894231593713745 0.010544913801602301\n",
            "K=  45\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "45 0.014628056625952485 0.0184283657482458\n",
            "K=  46\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "46 0.016006089894197134 0.00860535707031998\n",
            "K=  47\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "47 0.005164270989873626 0.02069721029341684\n",
            "K=  48\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00025: early stopping\n",
            "48 0.017025462713852108 0.02252002781990803\n",
            "K=  49\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "49 0.016333301252570626 0.02142357537682832\n",
            "K=  50\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "50 0.005366560920024882 0.03461804713322894\n",
            "K=  51\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "51 0.005412290491847577 0.012143382632996524\n",
            "K=  52\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00028: early stopping\n",
            "52 0.00674704662329817 0.013078167352535808\n",
            "K=  53\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00069: early stopping\n",
            "53 0.015212033608333203 0.014660433811525625\n",
            "K=  54\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00028: early stopping\n",
            "54 0.008744809812832405 0.015205897049410971\n",
            "K=  55\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00021: early stopping\n",
            "55 0.019762545978449397 0.01725167810548911\n",
            "K=  56\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "56 0.017528861740662954 0.021950927887047278\n",
            "K=  57\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "57 0.012813807236871727 0.017964326053075602\n",
            "K=  58\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "58 0.01894057055653381 0.023799692754654073\n",
            "K=  59\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00035: early stopping\n",
            "59 0.0042705277470968805 0.010628529930355873\n",
            "K=  60\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "60 0.018288326472054944 0.016897816043484143\n",
            "K=  61\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00053: early stopping\n",
            "61 0.014120221802318256 0.016566958406903365\n",
            "K=  62\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00066: early stopping\n",
            "62 0.012606999660742607 0.01745871227417581\n",
            "K=  63\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "63 0.008082677351196083 0.014126795776110063\n",
            "K=  64\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00029: early stopping\n",
            "64 0.014583794663136168 0.016866476636390015\n",
            "K=  65\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "65 0.031481039404729697 0.012194898077992122\n",
            "K=  66\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00062: early stopping\n",
            "66 0.00530172515865443 0.010691720671594018\n",
            "K=  67\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "67 0.008910112346161903 0.014773681261855076\n",
            "K=  68\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "68 0.009174226052239193 0.012375499331667678\n",
            "K=  69\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00040: early stopping\n",
            "69 0.012907286292523718 0.01692024757973798\n",
            "K=  70\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "70 0.011050610256070681 0.012997561138076152\n",
            "K=  71\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "71 0.007904282916212368 0.019036428520526366\n",
            "K=  72\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "72 0.01282733447913495 0.017140697357281437\n",
            "K=  73\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00040: early stopping\n",
            "73 0.012789676830886304 0.0159976444233412\n",
            "K=  74\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "74 0.019181700020404646 0.02310149062343861\n",
            "K=  75\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00036: early stopping\n",
            "75 0.005246714542525094 0.007413545705437147\n",
            "K=  76\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n",
            "76 0.019872068081665556 0.022008411729542043\n",
            "K=  77\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "77 0.024655043965151363 0.01819144278629578\n",
            "K=  78\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00044: early stopping\n",
            "78 0.016171792157076537 0.018736057555545776\n",
            "K=  79\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "79 0.033081425241910004 0.019616792394168664\n",
            "K=  80\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00036: early stopping\n",
            "80 0.01651525088735964 0.01781641263914696\n",
            "K=  81\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00055: early stopping\n",
            "81 0.009664447877620247 0.02252298597613525\n",
            "K=  82\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00036: early stopping\n",
            "82 0.017595818341767405 0.022944498923531842\n",
            "K=  83\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00027: early stopping\n",
            "83 0.019957172495067038 0.026708943170238086\n",
            "K=  84\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "84 0.013726479870016073 0.017259997620482914\n",
            "K=  85\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00053: early stopping\n",
            "85 0.005209488113224359 0.014739819026548362\n",
            "K=  86\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "86 0.006844923810415127 0.012750449866936797\n",
            "K=  87\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00025: early stopping\n",
            "87 0.006280376496527629 0.014664575117913303\n",
            "K=  88\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00039: early stopping\n",
            "88 0.01591019286389808 0.02079092330369678\n",
            "K=  89\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00037: early stopping\n",
            "89 0.010247687684786372 0.015948733660467507\n",
            "K=  90\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "90 0.011036430868960112 0.01681495436987626\n",
            "K=  91\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00044: early stopping\n",
            "91 0.002861722271417899 0.011419414302008185\n",
            "K=  92\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00030: early stopping\n",
            "92 0.010246434795107645 0.01732149211709183\n",
            "K=  93\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00038: early stopping\n",
            "93 0.011056870209508601 0.014252193737416513\n",
            "K=  94\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00035: early stopping\n",
            "94 0.016955023146922793 0.01763939130313283\n",
            "K=  95\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00038: early stopping\n",
            "95 0.005712780713955923 0.009356658083062963\n",
            "K=  96\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "96 0.025108434830190082 0.014683048028757112\n",
            "K=  97\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00039: early stopping\n",
            "97 0.013901588990225783 0.016223525811711964\n",
            "K=  98\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "98 0.01121790357244623 0.01998492497895324\n",
            "K=  99\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "99 0.00881360085759178 0.02270280632148397\n",
            "MAAE NN 0.012801742033879016\n",
            "MAAE CWO 0.017062675744696887\n",
            "MAAE NN: 0.01280\n",
            "MAAE CWO: 0.01706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpq4HcWkJwWy"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}